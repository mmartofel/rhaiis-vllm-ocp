NAMESPACE=vllm-inference
HF_DIR=/models-cache
PVC_SIZE=30Gi
MODEL_ID="Qwen/Qwen2.5-7B-Instruct-AWQ"
RHIIS_IMAGE="registry.redhat.io/rhaiis/vllm-cuda-rhel9:3"
HF_TOKEN=hf_<your_token>
